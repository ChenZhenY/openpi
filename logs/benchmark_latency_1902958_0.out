======================================
Array Task ID: 0
Running with batch_size=1 and port=8000
======================================
Starting background process: uv run scripts/serve_policy.py     --env=LIBERO_REALTIME     --batch_size=1     --port=8000
Background process started with PID: 1085656
Running benchmark...
Namespace(host='localhost', port=8000, env='libero', num_requests=300, request_rate=5.0, max_concurrency=100, disable_tqdm=False, metric_percentiles='95,99', save_result=True, save_result_dir='benchmarks/latency_batching/realtime_fake_batch', seed=0)
Connecting to server at ws://localhost:8000...
Server metadata: {'num_steps': 10, 'action_horizon': 50, 'env': 'libero_realtime', 'batch_size': 1}
Running warm-up request...
Warm-up completed.
Generating 300 observations...
Starting benchmark...
Request rate: 5.0 req/s
Max concurrency: 100
=============== Benchmark Results ================
Total requests:                          300       
Successful requests:                     300       
Failed requests:                         0         
Benchmark duration (s):                  60.13     
Request throughput (req/s):              4.99      
--------------- Latency Statistics ---------------
Mean latency (ms):                       71.33     
Median latency (ms):                     63.37     
Std latency (ms):                        21.15     
P95 latency (ms):                        113.61    
P99 latency (ms):                        145.52    
==================================================

Results saved to: benchmarks/latency_batching/realtime_fake_batch/benchmark-libero-20251105-165252.json
Namespace(host='localhost', port=8000, env='libero', num_requests=300, request_rate=10.0, max_concurrency=100, disable_tqdm=False, metric_percentiles='95,99', save_result=True, save_result_dir='benchmarks/latency_batching/realtime_fake_batch', seed=0)
Connecting to server at ws://localhost:8000...
Server metadata: {'num_steps': 10, 'action_horizon': 50, 'env': 'libero_realtime', 'batch_size': 1}
Running warm-up request...
Warm-up completed.
Generating 300 observations...
Starting benchmark...
Request rate: 10.0 req/s
Max concurrency: 100
=============== Benchmark Results ================
Total requests:                          300       
Successful requests:                     300       
Failed requests:                         0         
Benchmark duration (s):                  30.19     
Request throughput (req/s):              9.94      
--------------- Latency Statistics ---------------
Mean latency (ms):                       98.64     
Median latency (ms):                     78.41     
Std latency (ms):                        49.57     
P95 latency (ms):                        193.64    
P99 latency (ms):                        289.99    
==================================================

Results saved to: benchmarks/latency_batching/realtime_fake_batch/benchmark-libero-20251105-165329.json
Namespace(host='localhost', port=8000, env='libero', num_requests=300, request_rate=20.0, max_concurrency=100, disable_tqdm=False, metric_percentiles='95,99', save_result=True, save_result_dir='benchmarks/latency_batching/realtime_fake_batch', seed=0)
Connecting to server at ws://localhost:8000...
Server metadata: {'num_steps': 10, 'action_horizon': 50, 'env': 'libero_realtime', 'batch_size': 1}
Running warm-up request...
Warm-up completed.
Generating 300 observations...
Starting benchmark...
Request rate: 20.0 req/s
Max concurrency: 100
=============== Benchmark Results ================
Total requests:                          300       
Successful requests:                     300       
Failed requests:                         0         
Benchmark duration (s):                  17.66     
Request throughput (req/s):              16.99     
--------------- Latency Statistics ---------------
Mean latency (ms):                       1685.97   
Median latency (ms):                     1883.21   
Std latency (ms):                        740.90    
P95 latency (ms):                        2711.07   
P99 latency (ms):                        2808.87   
==================================================

Results saved to: benchmarks/latency_batching/realtime_fake_batch/benchmark-libero-20251105-165354.json
Namespace(host='localhost', port=8000, env='libero', num_requests=300, request_rate=50.0, max_concurrency=100, disable_tqdm=False, metric_percentiles='95,99', save_result=True, save_result_dir='benchmarks/latency_batching/realtime_fake_batch', seed=0)
Connecting to server at ws://localhost:8000...
Server metadata: {'num_steps': 10, 'action_horizon': 50, 'env': 'libero_realtime', 'batch_size': 1}
Running warm-up request...
Warm-up completed.
Generating 300 observations...
Starting benchmark...
Request rate: 50.0 req/s
Max concurrency: 100
=============== Benchmark Results ================
Total requests:                          300       
Successful requests:                     300       
Failed requests:                         0         
Benchmark duration (s):                  17.78     
Request throughput (req/s):              16.87     
--------------- Latency Statistics ---------------
Mean latency (ms):                       4514.33   
Median latency (ms):                     5905.40   
Std latency (ms):                        1864.22   
P95 latency (ms):                        5933.37   
P99 latency (ms):                        5939.71   
==================================================

Results saved to: benchmarks/latency_batching/realtime_fake_batch/benchmark-libero-20251105-165419.json
Namespace(host='localhost', port=8000, env='libero', num_requests=300, request_rate=100.0, max_concurrency=100, disable_tqdm=False, metric_percentiles='95,99', save_result=True, save_result_dir='benchmarks/latency_batching/realtime_fake_batch', seed=0)
Connecting to server at ws://localhost:8000...
Server metadata: {'num_steps': 10, 'action_horizon': 50, 'env': 'libero_realtime', 'batch_size': 1}
Running warm-up request...
Warm-up completed.
Generating 300 observations...
Starting benchmark...
Request rate: 100.0 req/s
Max concurrency: 100
=============== Benchmark Results ================
Total requests:                          300       
Successful requests:                     300       
Failed requests:                         0         
Benchmark duration (s):                  17.98     
Request throughput (req/s):              16.68     
--------------- Latency Statistics ---------------
Mean latency (ms):                       4821.56   
Median latency (ms):                     5975.01   
Std latency (ms):                        1803.71   
P95 latency (ms):                        6017.38   
P99 latency (ms):                        6019.60   
==================================================

Results saved to: benchmarks/latency_batching/realtime_fake_batch/benchmark-libero-20251105-165444.json
Cleaning up...
Stopping background process (PID: 1085656)
Cleanup complete
