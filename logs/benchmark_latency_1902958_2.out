======================================
Array Task ID: 2
Running with batch_size=4 and port=8002
======================================
Starting background process: uv run scripts/serve_policy.py     --env=LIBERO_REALTIME     --batch_size=4     --port=8002
Background process started with PID: 1085657
Running benchmark...
Namespace(host='localhost', port=8002, env='libero', num_requests=300, request_rate=5.0, max_concurrency=100, disable_tqdm=False, metric_percentiles='95,99', save_result=True, save_result_dir='benchmarks/latency_batching/realtime_fake_batch', seed=0)
Connecting to server at ws://localhost:8002...
Server metadata: {'num_steps': 10, 'action_horizon': 50, 'env': 'libero_realtime', 'batch_size': 4}
Running warm-up request...
Warm-up completed.
Generating 300 observations...
Starting benchmark...
Request rate: 5.0 req/s
Max concurrency: 100
=============== Benchmark Results ================
Total requests:                          300       
Successful requests:                     300       
Failed requests:                         0         
Benchmark duration (s):                  60.33     
Request throughput (req/s):              4.97      
--------------- Latency Statistics ---------------
Mean latency (ms):                       307.31    
Median latency (ms):                     294.21    
Std latency (ms):                        74.89     
P95 latency (ms):                        431.90    
P99 latency (ms):                        440.18    
==================================================

Results saved to: benchmarks/latency_batching/realtime_fake_batch/benchmark-libero-20251105-165150.json
Namespace(host='localhost', port=8002, env='libero', num_requests=300, request_rate=10.0, max_concurrency=100, disable_tqdm=False, metric_percentiles='95,99', save_result=True, save_result_dir='benchmarks/latency_batching/realtime_fake_batch', seed=0)
Connecting to server at ws://localhost:8002...
Server metadata: {'num_steps': 10, 'action_horizon': 50, 'env': 'libero_realtime', 'batch_size': 4}
Running warm-up request...
Warm-up completed.
Generating 300 observations...
Starting benchmark...
Request rate: 10.0 req/s
Max concurrency: 100
=============== Benchmark Results ================
Total requests:                          300       
Successful requests:                     300       
Failed requests:                         0         
Benchmark duration (s):                  30.48     
Request throughput (req/s):              9.84      
--------------- Latency Statistics ---------------
Mean latency (ms):                       346.02    
Median latency (ms):                     348.54    
Std latency (ms):                        77.47     
P95 latency (ms):                        455.10    
P99 latency (ms):                        523.92    
==================================================

Results saved to: benchmarks/latency_batching/realtime_fake_batch/benchmark-libero-20251105-165228.json
Namespace(host='localhost', port=8002, env='libero', num_requests=300, request_rate=20.0, max_concurrency=100, disable_tqdm=False, metric_percentiles='95,99', save_result=True, save_result_dir='benchmarks/latency_batching/realtime_fake_batch', seed=0)
Connecting to server at ws://localhost:8002...
Server metadata: {'num_steps': 10, 'action_horizon': 50, 'env': 'libero_realtime', 'batch_size': 4}
Running warm-up request...
Warm-up completed.
Generating 300 observations...
Starting benchmark...
Request rate: 20.0 req/s
Max concurrency: 100
=============== Benchmark Results ================
Total requests:                          300       
Successful requests:                     300       
Failed requests:                         0         
Benchmark duration (s):                  16.99     
Request throughput (req/s):              17.66     
--------------- Latency Statistics ---------------
Mean latency (ms):                       1495.58   
Median latency (ms):                     1578.00   
Std latency (ms):                        513.90    
P95 latency (ms):                        2292.29   
P99 latency (ms):                        2428.98   
==================================================

Results saved to: benchmarks/latency_batching/realtime_fake_batch/benchmark-libero-20251105-165253.json
Namespace(host='localhost', port=8002, env='libero', num_requests=300, request_rate=50.0, max_concurrency=100, disable_tqdm=False, metric_percentiles='95,99', save_result=True, save_result_dir='benchmarks/latency_batching/realtime_fake_batch', seed=0)
Connecting to server at ws://localhost:8002...
Server metadata: {'num_steps': 10, 'action_horizon': 50, 'env': 'libero_realtime', 'batch_size': 4}
Running warm-up request...
Warm-up completed.
Generating 300 observations...
Starting benchmark...
Request rate: 50.0 req/s
Max concurrency: 100
=============== Benchmark Results ================
Total requests:                          300       
Successful requests:                     300       
Failed requests:                         0         
Benchmark duration (s):                  17.07     
Request throughput (req/s):              17.57     
--------------- Latency Statistics ---------------
Mean latency (ms):                       4364.58   
Median latency (ms):                     5601.47   
Std latency (ms):                        1675.13   
P95 latency (ms):                        5612.85   
P99 latency (ms):                        5613.82   
==================================================

Results saved to: benchmarks/latency_batching/realtime_fake_batch/benchmark-libero-20251105-165317.json
Namespace(host='localhost', port=8002, env='libero', num_requests=300, request_rate=100.0, max_concurrency=100, disable_tqdm=False, metric_percentiles='95,99', save_result=True, save_result_dir='benchmarks/latency_batching/realtime_fake_batch', seed=0)
Connecting to server at ws://localhost:8002...
Server metadata: {'num_steps': 10, 'action_horizon': 50, 'env': 'libero_realtime', 'batch_size': 4}
Running warm-up request...
Warm-up completed.
Generating 300 observations...
Starting benchmark...
Request rate: 100.0 req/s
Max concurrency: 100
=============== Benchmark Results ================
Total requests:                          300       
Successful requests:                     300       
Failed requests:                         0         
Benchmark duration (s):                  17.06     
Request throughput (req/s):              17.59     
--------------- Latency Statistics ---------------
Mean latency (ms):                       4594.18   
Median latency (ms):                     5585.78   
Std latency (ms):                        1587.29   
P95 latency (ms):                        5610.87   
P99 latency (ms):                        5613.50   
==================================================

Results saved to: benchmarks/latency_batching/realtime_fake_batch/benchmark-libero-20251105-165341.json
Cleaning up...
Stopping background process (PID: 1085657)
Cleanup complete
