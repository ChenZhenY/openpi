======================================
Array Task ID: 1
Running with batch_size=2 and port=8001
======================================
Starting background process: uv run scripts/serve_policy.py     --env=LIBERO_REALTIME     --batch_size=2     --port=8001
Background process started with PID: 1085655
Running benchmark...
Namespace(host='localhost', port=8001, env='libero', num_requests=300, request_rate=5.0, max_concurrency=100, disable_tqdm=False, metric_percentiles='95,99', save_result=True, save_result_dir='benchmarks/latency_batching/realtime_fake_batch', seed=0)
Connecting to server at ws://localhost:8001...
Server metadata: {'num_steps': 10, 'action_horizon': 50, 'env': 'libero_realtime', 'batch_size': 2}
Running warm-up request...
Warm-up completed.
Generating 300 observations...
Starting benchmark...
Request rate: 5.0 req/s
Max concurrency: 100
=============== Benchmark Results ================
Total requests:                          300       
Successful requests:                     300       
Failed requests:                         0         
Benchmark duration (s):                  60.21     
Request throughput (req/s):              4.98      
--------------- Latency Statistics ---------------
Mean latency (ms):                       141.45    
Median latency (ms):                     118.28    
Std latency (ms):                        35.93     
P95 latency (ms):                        216.09    
P99 latency (ms):                        246.26    
==================================================

Results saved to: benchmarks/latency_batching/realtime_fake_batch/benchmark-libero-20251105-165221.json
Namespace(host='localhost', port=8001, env='libero', num_requests=300, request_rate=10.0, max_concurrency=100, disable_tqdm=False, metric_percentiles='95,99', save_result=True, save_result_dir='benchmarks/latency_batching/realtime_fake_batch', seed=0)
Connecting to server at ws://localhost:8001...
Server metadata: {'num_steps': 10, 'action_horizon': 50, 'env': 'libero_realtime', 'batch_size': 2}
Running warm-up request...
Warm-up completed.
Generating 300 observations...
Starting benchmark...
Request rate: 10.0 req/s
Max concurrency: 100
=============== Benchmark Results ================
Total requests:                          300       
Successful requests:                     300       
Failed requests:                         0         
Benchmark duration (s):                  30.30     
Request throughput (req/s):              9.90      
--------------- Latency Statistics ---------------
Mean latency (ms):                       177.55    
Median latency (ms):                     175.34    
Std latency (ms):                        55.11     
P95 latency (ms):                        278.52    
P99 latency (ms):                        347.57    
==================================================

Results saved to: benchmarks/latency_batching/realtime_fake_batch/benchmark-libero-20251105-165258.json
Namespace(host='localhost', port=8001, env='libero', num_requests=300, request_rate=20.0, max_concurrency=100, disable_tqdm=False, metric_percentiles='95,99', save_result=True, save_result_dir='benchmarks/latency_batching/realtime_fake_batch', seed=0)
Connecting to server at ws://localhost:8001...
Server metadata: {'num_steps': 10, 'action_horizon': 50, 'env': 'libero_realtime', 'batch_size': 2}
Running warm-up request...
Warm-up completed.
Generating 300 observations...
Starting benchmark...
Request rate: 20.0 req/s
Max concurrency: 100
=============== Benchmark Results ================
Total requests:                          300       
Successful requests:                     300       
Failed requests:                         0         
Benchmark duration (s):                  17.02     
Request throughput (req/s):              17.63     
--------------- Latency Statistics ---------------
Mean latency (ms):                       1397.47   
Median latency (ms):                     1514.11   
Std latency (ms):                        545.14    
P95 latency (ms):                        2239.81   
P99 latency (ms):                        2323.38   
==================================================

Results saved to: benchmarks/latency_batching/realtime_fake_batch/benchmark-libero-20251105-165322.json
Namespace(host='localhost', port=8001, env='libero', num_requests=300, request_rate=50.0, max_concurrency=100, disable_tqdm=False, metric_percentiles='95,99', save_result=True, save_result_dir='benchmarks/latency_batching/realtime_fake_batch', seed=0)
Connecting to server at ws://localhost:8001...
Server metadata: {'num_steps': 10, 'action_horizon': 50, 'env': 'libero_realtime', 'batch_size': 2}
Running warm-up request...
Warm-up completed.
Generating 300 observations...
Starting benchmark...
Request rate: 50.0 req/s
Max concurrency: 100
=============== Benchmark Results ================
Total requests:                          300       
Successful requests:                     300       
Failed requests:                         0         
Benchmark duration (s):                  17.14     
Request throughput (req/s):              17.51     
--------------- Latency Statistics ---------------
Mean latency (ms):                       4338.50   
Median latency (ms):                     5655.26   
Std latency (ms):                        1764.07   
P95 latency (ms):                        5689.54   
P99 latency (ms):                        5692.58   
==================================================

Results saved to: benchmarks/latency_batching/realtime_fake_batch/benchmark-libero-20251105-165347.json
Namespace(host='localhost', port=8001, env='libero', num_requests=300, request_rate=100.0, max_concurrency=100, disable_tqdm=False, metric_percentiles='95,99', save_result=True, save_result_dir='benchmarks/latency_batching/realtime_fake_batch', seed=0)
Connecting to server at ws://localhost:8001...
Server metadata: {'num_steps': 10, 'action_horizon': 50, 'env': 'libero_realtime', 'batch_size': 2}
Running warm-up request...
Warm-up completed.
Generating 300 observations...
Starting benchmark...
Request rate: 100.0 req/s
Max concurrency: 100
=============== Benchmark Results ================
Total requests:                          300       
Successful requests:                     300       
Failed requests:                         0         
Benchmark duration (s):                  17.19     
Request throughput (req/s):              17.45     
--------------- Latency Statistics ---------------
Mean latency (ms):                       4601.60   
Median latency (ms):                     5647.97   
Std latency (ms):                        1672.77   
P95 latency (ms):                        5712.28   
P99 latency (ms):                        5717.52   
==================================================

Results saved to: benchmarks/latency_batching/realtime_fake_batch/benchmark-libero-20251105-165411.json
Cleaning up...
Stopping background process (PID: 1085655)
Cleanup complete
